{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test deployed web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses some duplicate questions and tests them against the deployed web application on AKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from utilities import text_to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the external url for the web application running on AKS cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_json = !kubectl get service azure-ml -o json\n",
    "service_dict = json.loads(''.join(service_json))\n",
    "app_url = service_dict['status']['loadBalancer']['ingress'][0]['ip']\n",
    "app_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly check if the web application is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = 'http://{}/score'.format(app_url)\n",
    "version_url = 'http://{}/version'.format(app_url)\n",
    "health_url = 'http://{}/'.format(app_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $health_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $version_url # Reports the lightgbm version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use one of the duplicate questions to test our web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_test_path = 'dupes_test.tsv'\n",
    "dupes_test = pd.read_csv(dupes_test_path, sep='\\t', encoding='latin1')\n",
    "text_to_score = dupes_test.iloc[0,4]\n",
    "text_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsontext = text_to_json(text_to_score)\n",
    "jsontext[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'content-type': 'application/json'}\n",
    "r = requests.post(scoring_url, data=jsontext, headers=headers) # Run the request twice since the first time takes a \n",
    "%time r = requests.post(scoring_url, data=jsontext, headers=headers) # little longer due to the loading of the model\n",
    "print(r)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few more duplicate questions and display their top 3 original matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_to_score = dupes_test.iloc[:5,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [requests.post(scoring_url, data=text_to_json(text), headers=headers) for text in dupes_to_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print top 3 matches for each duplicate question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[results[i].json()['result'][0][0:3] for i in range(0, len(results))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's quickly check what the request response performance is for the deployed model on AKS cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = list(map(text_to_json, dupes_to_score)) # Retrieve the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_results = list()\n",
    "for text in text_data:\n",
    "    res=%timeit -r 1 -o -q requests.post(scoring_url, data=text, headers=headers)\n",
    "    timer_results.append(res.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average time taken: {0:4.2f} ms'.format(10**3 * np.mean(timer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tested that the model works and we can now move on to the [next notebook to get a sense of its throughput](07_Speed_Test_WebApp.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
