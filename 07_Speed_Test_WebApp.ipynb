{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test deployed web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we test the latency of the deployed web application by sending a number of duplicate questions as asychronous requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "import urllib.request\n",
    "from timeit import default_timer\n",
    "\n",
    "import aiohttp\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "from utilities import text_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(aiohttp.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our deployed service with 100 calls. We will only have 4 requests concurrently at any time. We have only deployed one pod on one node and increasing the number of concurrent calls does not really increase throughput. Feel free to try different values and see how the service responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_REQUESTS = 100  # Total number of requests\n",
    "CONCURRENT_REQUESTS = 4   # Number of requests at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the IP address of our service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_json = !kubectl get service azure-ml -o json\n",
    "service_dict = json.loads(''.join(service_json))\n",
    "app_url = service_dict['status']['loadBalancer']['ingress'][0]['ip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_url = 'http://{}/score'.format(app_url)\n",
    "version_url = 'http://{}/version'.format(app_url)\n",
    "health_url = 'http://{}/'.format(app_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl $health_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl $version_url # Reports the lightgbm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dupes_test_path = 'dupes_test.tsv'\n",
    "dupes_test = pd.read_csv(dupes_test_path, sep='\\t', encoding='latin1')\n",
    "dupes_to_score = dupes_test.iloc[:NUMBER_OF_REQUESTS,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_list = [[scoring_url, jsontext] for jsontext in dupes_to_score.apply(text_to_json)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(result):\n",
    "    return json.loads(result.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def fetch(url, session, data, headers):\n",
    "    start_time = default_timer()\n",
    "    async with session.request('post', url, data=data, headers=headers) as response:\n",
    "        resp = await response.read()\n",
    "        elapsed = default_timer() - start_time\n",
    "        return resp, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def bound_fetch(sem, url, session, data, headers):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        return await fetch(url, session, data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def await_with_progress(coros):\n",
    "    results=[]\n",
    "    for f in tqdm(asyncio.as_completed(coros), total=len(coros)):\n",
    "        result = await f\n",
    "        results.append((decode(result[0]),result[1]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def run(url_list, num_concurrent=CONCURRENT_REQUESTS):\n",
    "    headers = {'content-type': 'application/json', 'Authorization' : 'Bearer 4191d34b28ed4885a1ea0b141e0794ef'}\n",
    "    tasks = []\n",
    "    # create instance of Semaphore\n",
    "    sem = asyncio.Semaphore(num_concurrent)\n",
    "\n",
    "    # Create client session that will ensure we dont open new connection\n",
    "    # per each request.\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for url, data in url_list:\n",
    "            # pass Semaphore and session to every POST request\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session, data, headers))\n",
    "            tasks.append(task)\n",
    "        return await await_with_progress(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we run the 100 requests against our deployed service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "start_time = default_timer()\n",
    "complete_responses = loop.run_until_complete(asyncio.ensure_future(run(url_list, num_concurrent=CONCURRENT_REQUESTS)))\n",
    "elapsed = default_timer() - start_time\n",
    "print('Total Elapsed {}'.format(elapsed))\n",
    "print('Avg time taken {0:4.2f} ms'.format(1000*elapsed/len(url_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example response\n",
    "complete_responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the number of original questions to count the succesful responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_questions = len(complete_responses[0][0]['result'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_succesful=[len(i[0]['result'][0]) for i in complete_responses].count(no_questions)\n",
    "print('Succesful {} out of {}'.format(num_succesful, len(url_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will explore the real-time scoring in an [iPyWidget app](08_Real_Time_Scoring.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
